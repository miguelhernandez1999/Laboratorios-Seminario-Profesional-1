{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "laboratorio8__autoencoder_Miguel_h.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelhernandez1999/Laboratorios-Seminario-Profesional-1/blob/master/laboratorio8__autoencoder_Miguel_h.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRhsFZ9v7scS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only works in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7roVcpI09zk6",
        "colab_type": "code",
        "outputId": "d65a463f-444c-4016-970e-ac09ff971fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/SP1_2020/autoencoder/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzORkJiDApa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjFkvFd-AqcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvAutoencoder:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, filters=(32, 64), latentDim=16):\n",
        "        # initialize the input shape to be \"channels last\" along with\n",
        "        # the channels dimension itself\n",
        "        # channels dimension itself\n",
        "        inputShape = (height, width, depth)\n",
        "        chanDim = -1\n",
        "\n",
        "        # define the input to the encoder\n",
        "        inputs = Input(shape=inputShape)\n",
        "        x = inputs\n",
        "\n",
        "        # loop over the number of filters\n",
        "        for f in filters:\n",
        "            # apply a CONV => RELU => BN operation\n",
        "            x = Conv2D(f, (3, 3), strides=2, padding=\"same\")(x)\n",
        "            x = LeakyReLU(alpha=0.2)(x)\n",
        "            x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "        # flatten the network and then construct our latent vector\n",
        "        volumeSize = K.int_shape(x)\n",
        "        print(\"volumeSize:\",volumeSize)\n",
        "        x = Flatten()(x)\n",
        "        print(\"x shape\", K.int_shape(x))\n",
        "        latent = Dense(latentDim)(x)\n",
        "\n",
        "        # build the encoder model\n",
        "        encoder = Model(inputs, latent, name=\"encoder\")\n",
        "\n",
        "        # start building the decoder model which will accept the\n",
        "        # output of the encoder as its inputs\n",
        "        latentInputs = Input(shape=(latentDim,))\n",
        "        x = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
        "        print(\"prod shape:\",np.prod(volumeSize[1:]))\n",
        "        print(\"x shape\",K.int_shape(x))\n",
        "        x = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
        "        print(\"x shape\",K.int_shape(x))\n",
        "        # loop over our number of filters again, but this time in\n",
        "        # reverse order\n",
        "        for f in filters[::-1]:\n",
        "            # apply a CONV_TRANSPOSE => RELU => BN operation\n",
        "            x = Conv2DTranspose(f, (3, 3), strides=2,\n",
        "                padding=\"same\")(x)\n",
        "            x = LeakyReLU(alpha=0.2)(x)\n",
        "            x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "        # apply a single CONV_TRANSPOSE layer used to recover the\n",
        "        # original depth of the image\n",
        "        x = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n",
        "        outputs = Activation(\"sigmoid\")(x)\n",
        "\n",
        "        # build the decoder model\n",
        "        decoder = Model(latentInputs, outputs, name=\"decoder\")\n",
        "\n",
        "        # our autoencoder is the encoder + decoder\n",
        "        autoencoder = Model(inputs, decoder(encoder(inputs)),\n",
        "            name=\"autoencoder\")\n",
        "\n",
        "        # return a 3-tuple of the encoder, decoder, and autoencoder\n",
        "        return (encoder, decoder, autoencoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89D2AFBp9HIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "#from pyimagesearch.convautoencoder import ConvAutoencoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKpO3AW6-ELO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_unsupervised_dataset(data, labels, validLabel=1,\n",
        "    anomalyLabel=3, contam=0.01, seed=42):\n",
        "    # grab all indexes of the supplied class label that are *truly*\n",
        "    # that particular label, then grab the indexes of the image\n",
        "    # labels that will serve as our \"anomalies\"\n",
        "    validIdxs = np.where(labels == validLabel)[0]\n",
        "    anomalyIdxs = np.where(labels == anomalyLabel)[0]\n",
        "\n",
        "    # randomly shuffle both sets of indexes\n",
        "    random.shuffle(validIdxs)\n",
        "    random.shuffle(anomalyIdxs)\n",
        "\n",
        "    # compute the total number of anomaly data points to select\n",
        "    i = int(len(validIdxs) * contam)\n",
        "    anomalyIdxs = anomalyIdxs[:i]\n",
        "\n",
        "    # use NumPy array indexing to extract both the valid images and\n",
        "    # \"anomlay\" images\n",
        "    validImages = data[validIdxs]\n",
        "    anomalyImages = data[anomalyIdxs]\n",
        "\n",
        "    # stack the valid images and anomaly images together to form a\n",
        "    # single data matrix and then shuffle the rows\n",
        "    images = np.vstack([validImages, anomalyImages])\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(images)\n",
        "\n",
        "    # return the set of images\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUWYKH3R-HUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_predictions(decoded, gt, samples=10):\n",
        "    # initialize our list of output images\n",
        "    outputs = None\n",
        "\n",
        "    # loop over our number of output samples\n",
        "    for i in range(0, samples):\n",
        "        # grab the original image and reconstructed image\n",
        "        original = (gt[i] * 255).astype(\"uint8\")\n",
        "        recon = (decoded[i] * 255).astype(\"uint8\")\n",
        "\n",
        "        # stack the original and reconstructed image side-by-side\n",
        "        output = np.hstack([original, recon])\n",
        "\n",
        "        # if the outputs array is empty, initialize it as the current\n",
        "        # side-by-side image display\n",
        "        if outputs is None:\n",
        "            outputs = output\n",
        "\n",
        "        # otherwise, vertically stack the outputs\n",
        "        else:\n",
        "            outputs = np.vstack([outputs, output])\n",
        "\n",
        "    # return the output images\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aQ6Re9c-Y5d",
        "colab_type": "code",
        "outputId": "87e99c4a-ea88-4637-b3b9-8a5860b78f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "# initialize the number of epochs to train for, initial learning rate,\n",
        "# and batch size\n",
        "EPOCHS = 20\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "\n",
        "# load the MNIST dataset\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
        "\n",
        "# build our unsupervised dataset of images with a small amount of\n",
        "# contamination (i.e., anomalies) added into it\n",
        "print(\"[INFO] creating unsupervised dataset...\")\n",
        "images = build_unsupervised_dataset(trainX, trainY, validLabel=1,\n",
        "    anomalyLabel=3, contam=0.01)\n",
        "\n",
        "# add a channel dimension to every image in the dataset, then scale\n",
        "# the pixel intensities to the range [0, 1]\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "images = images.astype(\"float32\") / 255.0\n",
        "\n",
        "# construct the training and testing split\n",
        "(trainX, testX) = train_test_split(images, test_size=0.2,\n",
        "    random_state=42)\n",
        "\n",
        "# construct our convolutional autoencoder\n",
        "print(\"[INFO] building autoencoder...\")\n",
        "(encoder, decoder, autoencoder) = ConvAutoencoder.build(28, 28, 1)\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "autoencoder.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "# train the convolutional autoencoder\n",
        "H = autoencoder.fit(\n",
        "    trainX, trainX,\n",
        "    validation_data=(testX, testX),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BS)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "[INFO] creating unsupervised dataset...\n",
            "[INFO] building autoencoder...\n",
            "volumeSize: (None, 7, 7, 64)\n",
            "x shape (None, 3136)\n",
            "prod shape: 3136\n",
            "x shape (None, 3136)\n",
            "x shape (None, 7, 7, 64)\n",
            "Epoch 1/20\n",
            "152/152 [==============================] - 11s 73ms/step - loss: 0.0322 - val_loss: 0.1045\n",
            "Epoch 2/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0096 - val_loss: 0.0641\n",
            "Epoch 3/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0063 - val_loss: 0.0266\n",
            "Epoch 4/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0054 - val_loss: 0.0068\n",
            "Epoch 5/20\n",
            "152/152 [==============================] - 11s 71ms/step - loss: 0.0049 - val_loss: 0.0050\n",
            "Epoch 6/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 7/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0043 - val_loss: 0.0043\n",
            "Epoch 8/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0041 - val_loss: 0.0047\n",
            "Epoch 9/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 10/20\n",
            "152/152 [==============================] - 11s 71ms/step - loss: 0.0039 - val_loss: 0.0040\n",
            "Epoch 11/20\n",
            "152/152 [==============================] - 11s 71ms/step - loss: 0.0038 - val_loss: 0.0040\n",
            "Epoch 12/20\n",
            "152/152 [==============================] - 11s 71ms/step - loss: 0.0037 - val_loss: 0.0040\n",
            "Epoch 13/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0035 - val_loss: 0.0048\n",
            "Epoch 14/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0035 - val_loss: 0.0038\n",
            "Epoch 15/20\n",
            "152/152 [==============================] - 11s 71ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 16/20\n",
            "152/152 [==============================] - 11s 71ms/step - loss: 0.0033 - val_loss: 0.0035\n",
            "Epoch 17/20\n",
            "152/152 [==============================] - 11s 71ms/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 18/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 19/20\n",
            "152/152 [==============================] - 11s 72ms/step - loss: 0.0033 - val_loss: 0.0036\n",
            "Epoch 20/20\n",
            "152/152 [==============================] - 11s 71ms/step - loss: 0.0032 - val_loss: 0.0036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J3UcWAf-yIx",
        "colab_type": "code",
        "outputId": "9e581f64-7e90-4217-9955-9cc2236e4803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# use the convolutional autoencoder to make predictions on the\n",
        "# testing images, construct the visualization, and then save it\n",
        "# to disk\n",
        "print(\"[INFO] making predictions...\")\n",
        "decoded = autoencoder.predict(testX)\n",
        "vis = visualize_predictions(decoded, testX)\n",
        "cv2.imwrite(\"/content/drive/My Drive/SP1_2020/autoencoder/encoder_vis.png\", vis)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] making predictions...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2L6JeLgJKme",
        "colab_type": "code",
        "outputId": "1fe16bfc-45fb-4558-8e10-602df78fe652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "img = cv2.imread('/content/drive/My Drive/SP1_2020/autoencoder/encoder_vis.png', cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-cd173fba9a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/SP1_2020/autoencoder/encoder_vis.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_UNCHANGED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKecfCn0_b2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "dc95667d-07aa-4230-e64d-d722c41c4fe0"
      },
      "source": [
        "# construct a plot that plots and saves the training history\n",
        "N = np.arange(0, EPOCHS)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"/content/drive/My Drive/SP1_2020/autoencoder/plot.png\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-29251713b8bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/SP1_2020/autoencoder/plot.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2103\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2106\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m                 _png.write_png(renderer._renderer, fh, self.figure.dpi,\n\u001b[1;32m    537\u001b[0m                                metadata={**default_metadata, **metadata})\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/SP1_2020/autoencoder/plot.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MHFtvBiH9Co",
        "colab_type": "code",
        "outputId": "b5e7ac0f-c5c3-4b84-ce41-8edcf5f45be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "img = cv2.imread('/content/drive/My Drive/SP1_2020/autoencoder/plot.png', cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0f44b0ab00dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/SP1_2020/autoencoder/plot.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_UNCHANGED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q7QfK9z71Jr",
        "colab_type": "code",
        "outputId": "12f92ece-aa5d-4e98-f917-03c2826becce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "# serialize the image data to disk\n",
        "print(\"[INFO] saving image data...\")\n",
        "f = open(\"/content/drive/My Drive/SP1_2020/autoencoder/output/images.pickle\", \"wb\")\n",
        "f.write(pickle.dumps(images))\n",
        "f.close()\n",
        "\n",
        "# serialize the autoencoder model to disk\n",
        "print(\"[INFO] saving autoencoder...\")\n",
        "autoencoder.save(\"/content/drive/My Drive/SP1_2020/autoencoder/output/autoencoder.model\", save_format=\"h5\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] saving image data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3c78d1f9031a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] saving image data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/SP1_2020/autoencoder/output/images.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/SP1_2020/autoencoder/output/images.pickle'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEdXVLGIGNge",
        "colab_type": "text"
      },
      "source": [
        "##**FIND ANOMALIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVIyGlmG4TC",
        "colab_type": "code",
        "outputId": "287a12ec-a50d-4594-9e4e-795daf1c8807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "#import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "\n",
        "# load the model and image data from disk\n",
        "print(\"[INFO] loading autoencoder and image data...\")\n",
        "autoencoder = load_model(\"/content/drive/My Drive/SP1_2020/autoencoder/output/autoencoder.model\")\n",
        "images = pickle.loads(open(\"/content/drive/My Drive/SP1_2020/autoencoder/output/images.pickle\", \"rb\").read())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading autoencoder and image data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-644c56a76607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load the model and image data from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] loading autoencoder and image data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/SP1_2020/autoencoder/output/autoencoder.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/SP1_2020/autoencoder/output/images.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/drive/My Drive/SP1_2020/autoencoder/output/autoencoder.model/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P60sfSsG8XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions on our image data and initialize our list of\n",
        "# reconstruction errors\n",
        "decoded = autoencoder.predict(images)\n",
        "errors = []\n",
        "\n",
        "# loop over all original images and their corresponding\n",
        "# reconstructions\n",
        "for (image, recon) in zip(images, decoded):\n",
        "    # compute the mean squared error between the ground-truth image\n",
        "    # and the reconstructed image, then add it to our list of errors\n",
        "    mse = np.mean((image - recon) ** 2)\n",
        "    errors.append(mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBCWx8G2HBtx",
        "colab_type": "code",
        "outputId": "58e18283-c5a0-460d-fdb4-b29375bedfa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# compute the q-th quantile of the errors which serves as our\n",
        "# threshold to identify anomalies -- any data point that our model\n",
        "# reconstructed with > threshold error will be marked as an outlier\n",
        "thresh = np.quantile(errors, 0.999)\n",
        "idxs = np.where(np.array(errors) >= thresh)[0]\n",
        "print(\"[INFO] mse threshold: {}\".format(thresh))\n",
        "print(\"[INFO] {} outliers found\".format(len(idxs)))\n",
        "\n",
        "# initialize the outputs array\n",
        "outputs = None"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] mse threshold: 0.036949119608849224\n",
            "[INFO] 7 outliers found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4USdkEm6-Bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loop over the indexes of images with a high mean squared error term\n",
        "for i in idxs:\n",
        "    # grab the original image and reconstructed image\n",
        "    original = (images[i] * 255).astype(\"uint8\")\n",
        "    recon = (decoded[i] * 255).astype(\"uint8\")\n",
        "\n",
        "    # stack the original and reconstructed image side-by-side\n",
        "    output = np.hstack([original, recon])\n",
        "\n",
        "    # if the outputs array is empty, initialize it as the current\n",
        "    # side-by-side image display\n",
        "    if outputs is None:\n",
        "        outputs = output\n",
        "\n",
        "    # otherwise, vertically stack the outputs\n",
        "    else:\n",
        "        outputs = np.vstack([outputs, output])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Owd5B7HtzO",
        "colab_type": "code",
        "outputId": "d2a9928b-6b5c-48c9-af3a-6361267d4aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "# show the output visualization\n",
        "cv2_imshow(outputs)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=56x196 at 0x7F39665D54A8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}