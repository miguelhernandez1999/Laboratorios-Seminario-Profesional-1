{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "laboratorio7_LSTM_Miguel_H.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelhernandez1999/Laboratorios-Seminario-Profesional-1/blob/master/laboratorio7_LSTM_Miguel_H.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FsrLXj2CyH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only works in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhB_N3oVCzqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn model for the har dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJqkUOWSJmba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = \"/content/drive/My Drive/SP1_2020/HAR with CNN/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O6cyb5PGFIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run this only once to save dataset to drive\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/HAR_Smartphones.zip -P \"/content/drive/My Drive/SP1_2020/HAR with CNN/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th5htJdGRSSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls -l \"/content/drive/My Drive/SP1_2020/HAR with CNN/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1jj5h-UHN5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q \"/content/drive/My Drive/SP1_2020/HAR with CNN/HAR_Smartphones.zip\" -d \"/content/drive/My Drive/SP1_2020/HAR with CNN/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ9Ij24xf_fJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "import datetime, os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQF0Hs2qfiPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "# checkpoint\n",
        "filepath = dataset_path + \"output.best.h5\"\n",
        "checkpoint_callback = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min',save_freq='epoch')\n",
        "\n",
        "# tensorboard\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=1,profile_batch=0)\n",
        "\n",
        "# callbacks\n",
        "callbacks_list = [checkpoint_callback,tensorboard_callback]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pR2KIMAgGmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run Tensorboad for monitoring\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbZXofR7C__X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
        "    return dataframe.values\n",
        "\n",
        "# load a list of files and return as a 3d numpy array\n",
        "def load_group(filenames, prefix=''):\n",
        "    loaded = list()\n",
        "\n",
        "    print(\"\\nShape dimensions:\\n\")\n",
        "    for name in filenames:\n",
        "        data = load_file(prefix + name)\n",
        "        print(np.array(loaded).shape)\n",
        "        loaded.append(data)\n",
        "      \n",
        "     \n",
        "    # stack group so that features are the 3rd dimension\n",
        "    print(np.array(loaded).shape)\n",
        "    loaded = np.dstack(loaded)\n",
        "    print(np.array(loaded).shape)\n",
        "    return loaded\n",
        "\n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "    filepath = prefix + group + '/Inertial Signals/'\n",
        "    # load all 9 files as a single array\n",
        "    filenames = list()\n",
        "    # total acceleration\n",
        "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "    # body acceleration\n",
        "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "    # body gyroscope\n",
        "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "    # load input data\n",
        "    X = load_group(filenames, filepath)\n",
        "    # load class output\n",
        "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "    return X, y\n",
        "\n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "    # load all train\n",
        "    trainX, trainy = load_dataset_group('train', prefix + 'UCI HAR Dataset/')\n",
        "    # load all test\n",
        "    testX, testy = load_dataset_group('test', prefix + 'UCI HAR Dataset/')\n",
        "    # zero-offset class values\n",
        "    trainy = trainy - 1\n",
        "    testy = testy - 1\n",
        "    print(\"\\nOne Hot Encoding: \\n\",trainy)\n",
        "    # one hot encode y\n",
        "    trainy = to_categorical(trainy)\n",
        "    testy = to_categorical(testy)\n",
        "    print(\"\\n\",trainy)\n",
        "    return trainX, trainy, testX, testy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToE5nuXuCmYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "    global model\n",
        "    verbose, epochs, batch_size = 1, 10, 32\n",
        "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "    \n",
        "    model.add(LSTM(4, input_shape=(n_timesteps, n_features)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "    # fit network\n",
        "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose,callbacks=callbacks_list)\n",
        "    # evaluate model\n",
        "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4nkoL6CVgtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX, trainy, testX, testy = load_dataset(\"/content/drive/My Drive/SP1_2020/HAR with CNN/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjDV3qWtVjU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = evaluate_model(trainX, trainy, testX, testy)\n",
        "score = score * 100.0\n",
        "print('>Accuracy: %.3f' % (score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJO0de2OWHNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\nsample:\", testX[0])\n",
        "print(\"\\nshape: \", testX[0].shape)\n",
        "print(\"\\nground truth: \", testy[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3eBPdb3ggzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model(dataset_path+'output.best.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Ag9rjdXAcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = testX[0]\n",
        "t = t.reshape(1,128,9)\n",
        "\n",
        "\n",
        "print(\"\\nclass:\",model.predict_classes(t))\n",
        "print(\"\\nprobs:\",model.predict_proba(t))\n",
        "\n",
        "#print(np.argmax(result))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}